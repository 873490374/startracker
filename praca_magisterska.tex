\documentclass[12pt,a4paper,oneside]{article}
\usepackage[utf8]{inputenc}
\usepackage[acronym, toc, nonumberlist, nogroupskip]{glossaries}

\usepackage[english, polish]{babel}
\usepackage[OT4]{fontenc}
\usepackage{lmodern}
\usepackage{textcomp, gensymb}

%%% fix for \lll
\let\babellll\lll
\let\lll\relax

\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{subfig}
\graphicspath{ {images/} }
\usepackage{amssymb}

\usepackage{enumitem}
\usepackage{scrextend}
\addtokomafont{labelinglabel}{\sffamily}


%%% fix for \lll
\let\mathlll\lll
\let\lll\babellll

\usepackage[nottoc]{tocbibind}
\usepackage{bm}
\makenoidxglossaries
\usepackage{filecontents}
\glsnoexpandfields
\usepackage[numbers]{natbib}

\setlength\headheight{15pt}
\enlargethispage*{0.7\baselineskip}




\pagestyle{fancy}
\fancyhf{}
\rhead{MICHALSKI Sz.}
\lhead{Star-tracker for Cubesat satellites}
%\lhead{Star-tracker dla Cubesat'ów}
\rfoot{\thepage}

\author{Szymon MICHALSKI}
\title{PROGRAM STAR-TRACKER DLA SATELITÓW TYPU CUBE-SAT}


\begin{filecontents}{gloss.tex}
%================ACRONYMS=================%
\newacronym{leo}{LEO}{Low Earth Orbit}
\newacronym{adcs}{ADCS}{Attitude Determination and Control System}
\newacronym{lis}{LIS}{Lost-In-Space}
\newacronym{gps}{GPS}{Global Positioning System}
%================SYMBOLS=================%
\newglossaryentry{phi}{type=symbols, name=$\phi$, sort=phi, description={Euler angle, roll}}
\newglossaryentry{theta}{type=symbols, name=$\theta$, sort=theta, description={Euler angle, pitch}}
\newglossaryentry{psi}{type=symbols, name=$\psi$, sort=psi, description={Euler angle, yaw}}
\newglossaryentry{euler_rotation_matrix}{type=symbols, name=$\bm{R}(\cdot)$, sort=euler_rotation_matrix, description={Rotation matrix using Euler angles}}
\newglossaryentry{unit_quaterion}{type=symbols, name=$\bm{q}$, sort=unit_quaterion, description={Unit quaternion}}
\newglossaryentry{scalar_quaternion_part}{type=symbols, name=$q_0$, sort=sigma, description={Scalar part of unit quaternion}}
\newglossaryentry{vector_quaternion_part}{type=symbols, name=$\bm{q}_{vec}$, sort=scalar_quaternion_part, description={Vector part of unit quaternion}}
\newglossaryentry{quaternion_matrix}{type=symbols, name=$\bm{Q}$, sort=quaternion_matrix, description={Quaternion matrix}}
\newglossaryentry{general_euler_angle}{type=symbols, name=$v$, sort=general_euler_angle, description={General Euler angle}}
\newglossaryentry{unit_vector}{type=symbols, name=$\bm{n}$, sort=unit_vector, description={Unit vector}}
\newglossaryentry{identity_matrix}{type=symbols, name=$\bm{I}$, sort=identity_matrix, description={Identity matrix}}
\newglossaryentry{skew_symmetrix_matrix}{type=symbols, name=$\bm{S}(\cdot)$, sort=skew_symmetrix_matrix, description={Skew symmetric matrix}}
\newglossaryentry{rotation_matrix}{type=symbols, name=$\bm{R}_n^b$, sort=rotation_matrix, description={Rotation matrix representing a rotation from n to b}}
\newglossaryentry{least_squares_estimate_rotation_matrix}{type=symbols, name=$\bm{M}$, sort=least_squares_estimate_rotation_matrix, description={Least squares estimate of rotation matrix}}
\newglossaryentry{unit_vector_ned}{type=symbols, name=$\bm{r}$, sort=unit_vector_ned, description={Known directional unit vector in the NED frame}}
\newglossaryentry{unit_vector_body}{type=symbols, name=$\bm{b}$, sort=unit_vector_body, description={Known directional unit vector in the BODY frame}}

\end{filecontents}

\newglossary{symbols}{sym}{sbl}{List of Symbols}
\makenoidxglossaries
\glsnoexpandfields
\loadglsentries{gloss.tex}


\begin{document}
\selectlanguage{english}

\begin{titlepage}
	\centering

	INSTITUTE OF CONTROL AND COMPUTATION ENGINEERING\par
	FACULTY OF ELECTRONICS AND INFORMATION TECHNOLOGY\par
	WARSAW UNIVERSITY OF TECHNOLOGY\par
%	INSTYTUT AUTOMATYKI I INFORMATYKI STOSOWANEJ\par
%	WYDZIAŁ ELEKTRONIKI I TECHNIK INFORMATYJNYCH\par
%	POLITECHNIKA WARSZAWSKA\par
	\vspace{0.5cm}
	\includegraphics[scale=0.3]{logo_WEiTI.jpg}
	\hspace{1cm}
	\includegraphics[scale=0.2]{Logo-PW-duze.jpg}
	\hspace{1cm}
	\includegraphics[scale=1]{ia_600_600.png}
	\par
	\vspace{2cm}
	MASTER OF SCIENCE THESIS\par
%	MAGISTERSKA PRACA DYPLOMOWA\par
	\vspace{0.2cm}
	{\huge STAR-TRACKER PROGRAM FOR CUBESAT SATELLITES\par}
%	{\huge PROGRAM STAR-TRACKER DLA SATELITÓW TYPU CUBE-SAT\par}
	\vspace{0.2cm}
	{\large Szymon MICHALSKI\par}
	\vspace{3cm}
	\begin{flushright}
	Supervisor:\par
%	Promotor:\par
	prof. dr hab. inż. Ryszard Romaniuk\par
	\end{flushright}
	\vspace{6cm}
	{\large Warszawa 2017\par}
\end{titlepage}

\pagenumbering{arabic}
\setcounter{page}{2}
\newpage
\begin{abstract}
Last years directed space industry towards small satellites. Many countries which did not have possibility to enter this branch of industry before now create their own solutions. The goal of this work is to create fully functioning star-tracker software eligible to be used in future satellites as Polish solution of determination of satellite attitude towards Earth. Work contains also description of individual parts and variants of solutions connected with star-tracker.
\end{abstract}
\newpage
\begin{otherlanguage}{polish}
\begin{abstract}
Ostatnie lata ukierunkowały przemysł kosmiczny na małe satelity. Wiele krajów, które wcześniej nie miały możliwości wejścia w tę gałąź przemysłu, teraz tworzą własne rozwiązania. Celem niniejszej pracy dyplomowej jest stworzenie w pełni działającego oprogramowania star-trackera nadającego się do wykorzystania w przyszłych satelitach jako polskie rozwiązanie problemu określania orientacji satelity względem ziemi. Praca zawiera też opis poszczególnych części i wariantów rozwiazania problemów związanych ze star-trackerem.
\end{abstract}
\end{otherlanguage}
\newpage

\tableofcontents

\newpage
\setlength{\parindent}{1cm}
\setlength{\parskip}{\baselineskip}%



\glsaddall
\setlength{\glsdescwidth}{0.5\linewidth}
\setlength{\glspagelistwidth}{0.1\linewidth}

\printnoidxglossary[type=acronym,sort=letter]
\newpage

\printnoidxglossary[type=symbols,sort=use]

\newpage


\section{Introduction}
Stars were used for navigation already ages ago. Together with technological development, spread of sailing and seafaring people started to use more advanced tools helping to more precisely estimate position of ships on sea. In XVIII century new tool was created, named sextant. This device helped to quite precisely calculate angle between the line ship-horizon and ship-star, what let to estimate position.

Nowadays, hundreds of years later, thanks to other technologies like for example Global Positioning System (GPS) stars are not necessary any more for travelling. As it is commonly known, GPS technology is based on satellites, and today those satellites need stars for determining their attitude towards Earth.

With the miniaturization of electronics and batteries new type of satellites was invented: CubeSat micro-satellite. They have now greater sensory and processing power possibilities, previously found only in larger satellites. However CubSats are still behind in terms of attitude determination.

\subsection{Motivation}
The goal of this work is to make fully operational star-tracker software, that could be used on Cubesat satellites. Such program could be used on space missions and could start Polish state-of-the-art technology in growing space technology sector.
There is already existing prototype of on-board computer for such CubeSat satellite, which together with this work should create full star-tracker device: hardware + software.

\subsection{Outline of thesis}

This thesis consists of several chapters. Here they are shortly summarized:\par
\setlength{\parindent}{0cm}
\textbf{Chapter 1} serves as introduction to this thesis and describes the motivation and goal of this work. It also describes the background of the topic.\par
\textbf{Chapter 2} describes all the important foundations for the fully understanding given work.\par
\textbf{Chapter 3} is the main part of this thesis. It describes how the star-tracker program works and goes through detailed comparison of different approaches.\par
\textbf{Chapter 4} describes the created prototype of star-tracker in Python language.\par
\textbf{Chapter 5} talks about the implementation of star-tracker on the existing prototype of on-board computer.\par
\textbf{Chapter 6} describes how the finished program is performing.\par
\textbf{Chapter 7} contains conclusions about this work and created star-tracker program.\par

\setlength{\parindent}{1cm}

\subsection{Related work}

There exists a number of works connected to topic of star-tracker. Many works are cited later in this thesis as they describe important parts of algorithms. There are just a few works dealing with whole start-tracker program, not just parts of it, and nearly no works about whole program together with implementation on the real equipment. The related work can be divided into few sections:

\begin{itemize}[noitemsep]
\item Works describing CubeSats in general: \citet{swartwout2011brief} and \citet{heidt2000cubesat}.

\item Algorithms for calculating star centroids: \citet{liebe2002accuracy}, \citet{samaan2002predictive}, \citet{knutson2012fast}, \citet{azizabadi2014vlsi}, \citet{lindh2014development} and \citet{zhang2014brightness}. 

\item Star identification (which star in image corresponds to which star in on-board catalogue) divided by design:
\begin{itemize}[noitemsep]
\item Planar Triangle - \citet{cole2006fast}, 
\item Spherical Triangle - \citet{cole2004fast}, 
\item Pyramid - \citet{mortari2004pyramid}, 
\item Geometric Voting - \citet{kolomenkin2008geometric}, 
\item Grid Algorithm - \citet{padgett1997grid}, 
\item Brightness Independent -  \citet{dong2006brightness},
\item SP-Search - \citet{mortari1999sp}, 
\item use of neural networks: 
\begin{itemize}[noitemsep]
\item \citet{miri2012star}, 
\item \citet{lindbladstar},
\item \citet{li2003star}, 
\end{itemize}
\item separately discussed k-vector algorithm for faster search:
\begin{itemize}[noitemsep]
\item \citet{mortari1996fast}, 
\item \citet{mortari2000k},
\item \citet{mortari2013k}. 
\end{itemize}
\end{itemize}

\item Attitude Determination divided by design: 
\begin{itemize}[noitemsep]
\item AIM (Attitude estimation using Image Matching) - \citet{delabie2012highly}, 
\item QUEST - \citet{shuster1990kalman}, 
\item QUEST improvement - \citet{cheng2014improvement}, 
\item Extended Quest - \citet{psiaki1999extended}, 
\item EQUEST - \citet{rinnan2012development}, 
\item Singular Value Decomposition - \citet{juang2003efficient}, 
\item Optimal Image Matching - \citet{delabie2012highly}
\item summarized description of attitude estimation algorithms: 
\begin{itemize}[noitemsep]
\item \citet{markley1999estimate},
\item \citet{hall2003spacecraft},
\item \citet{tappe2009development}.
\end{itemize}
\end{itemize}

\item Works on hardware for star-tracker \citet{azizabadi2014vlsi}, \citet{gaska2016obc}, \citet{felikson2011orbit}.

\item Works on full star tracker but without implementing on real device/ simulations only: \citet{kandiyil2010attitude}, \citet{huffman2006designing} and \citet{diaz2006performance}.

\item Full star-tracker with device/on real device \citet{jalabert2011optimization}, \citet{lizy2010str}, \citet{rose2003star}, \citet{mortari2002starnav} and
\citet{cannata2007autonomous}.

\end{itemize}

Many of those works will be mentioned and cited later in this thesis as they are crucial for this work and describe the ways how star-tracker should be designed. All those main algorithm types, like finding star centroids or star identification, are also described here in full detail in next sections.

\subsection{Cubesat}


In recent years there has been the development of micro-satellites called CubeSats. CubeSat is a standard created in 1999 at the California Polytechnic State University \cite{heidt2000cubesat}, which is used for low-cost micro-satellites. CubeSats are measured in units. Most are 1U, 2U and 3U. CubeSat 1U has a size of 10 cm on each edge and the maximum weight of 1.333 kg, while the CubeSat 2U is 20x10x10 cm and can weigh up to 2.666 kg.

The advantage of the standard is primarily reduction of the price of elevation of such satellites into orbit. Their popularity is evidenced by the fact that the percentage of satellites weighing less than 10 kg has increased to about 60\% of all satellites, and only CubeSats make up about half of the small satellites that were launched in last years \cite{swartwout2011brief}\cite{swartwout2013first}. Till now there were around 800 CubeSats launched \cite{nanosats}.

There exist wide range of CubeSat examples. Mostly they are scientific and students' satellites, for learning, experimental and science purposes. There are also few Polish examples: PW-SAT (1U) and PW-SAT 2 (2U) designed by students of Warsaw University of Technology, and Lem (8U) and Heweliusz (8U), both made at Polish Academy of Sciences. PW-SAT and PW-SAT 2 were used for learning and experimenting with new technologies, like deorbitation sail, solar sensor, etc. \cite{pw-sat2}.
Scientific satellites Lem and Heweliusz were built as part of BRITE programme - joint programme of Austria, Canada and Poland. The goal of this programme is to research mechanisms of energy transportation and angular momentum which happen inside hottest stars\cite{brite-pl}.

Typical CubeSat consist of many different components. Quite often it has antennas and radios for communication with mission centre on Earth, Electric Power System (EPS - subsystem responsible for managing electric power in the satellite), Attitude Determination and Control (ADCS - subsystem responsible for analysing data from sensors and taking decision about trajectory, etc.), magnetometer, star-tracker, sun sensors, payload processor with mission instructions, etc. CubeSats are quite small, hence they usually do not have any propulsion system. Figure \ref{fig:cubesat-build} shows the components of CubeSat on example of NASA's Interplanetary NanoSpacecraft Pathfinder In a Relevant Environment (INSPIRE).

\begin{figure}[!htbp]
  \centering
  \subfloat[PW-SAT \cite{pw-sat-image}]{\includegraphics[width=0.4\textwidth]{pw-sat.jpg}\label{fig:pw-sat}}
  \hfill
  \subfloat[PW-SAT 2 \cite{pw-sat2}]{\includegraphics[width=0.5\textwidth]{PW-Sat2_2016_16_MSwietlik.png}\label{fig:pw-sat2}}
  \hfill
  \subfloat[BRITE-PL (Lem, Heweliusz) \cite{brite-pl-gunter}]{\includegraphics[width=0.5\textwidth]{brite.jpg}\label{fig:brite}}
  \caption{Example of Polish CubeSats.}
  \label{fig:satellites-examples}
\end{figure}


\begin{figure}[!htbp]
\includegraphics[scale=0.45]{INSPIRE_JPL.jpg}
\centering
\caption{CubeSat build - INSPIRE, Image \cite{cubesat-build}}
\label{fig:cubesat-build}
\end{figure}

Costs of such CubeSat satellite on example of PW-SAT 2: 120,000-200,000 EUR for putting the satellite on the orbit and round 70,000 EUR for designing and building the satellite itself \cite{pw-pw-sat2}.


\subsection{Means of attitude determination}

Attitude of spaceships must be usually stabilised and controlled for various reasons.
It is necessary for satellite antenna to be pointing towards Earth for the proper communication, to intelligently control the heat by using the effects of cooling and heating of the shadows and sunlight, as well as to navigate: manoeuvres must be performed in the right direction.

Attitude is determined between two coordinate systems (where one is reference system) and defines by what angles the coordinate system connected with the researched object has to be shifted in order to cover the reference system.
Devices such as planes and satellites have so called Attitude Determination and Control System (ADCS), which controls attitude of object relative to an inertial reference frame or another entity (the celestial sphere, certain areas, the nearby objects, etc.).

Currently, attitude determination of CubeSats is limited mainly to the sun sensors, magnetometers and measurements of inertia. The following table describes the accuracy of different sensors. Unquestionable winner here is the star-tracker, which, due to its quality and uniqueness of the constellations is ideal for navigation. 

\subsubsection{Inertial Measurement Unit}
An Inertial Measurement Unit (IMU) detects linear acceleration using one or more accelerometers and rotational rate using gyroscopes, sometimes they also include magnetometers. They are commonly used in planes, spacecrafts and many consumer devices like smart-phones. The biggest disadvantage of IMU is accumulated error. Even small error that is accumulated with time brings device to think it is in different location than it actually is. Usually the errors are corrected via use of Kalman filter, which corrects IMU errors using other sources (i.e. GPS).
\subsubsection{Sun Sensors}
Sun sensors typically consist of few sensors oriented perpendicularly, which can tell the angle of the sun. They can give the information how the satellite is oriented towards the sun.
\subsubsection{Star-Tracker}
Star-tracker is quite sophisticated device, which consists of camera, processor and memory for database. In the database is catalogue of stars, built basing on data from Earth's observatories. Simply put star-tracker, when in orbit, takes picture of space - stars. Then processes the image to recognize stars in it and compares with data in catalogue or with previous image. When stars are identified star-tracker estimates the attitude of satellite towards Earth. The main advantage over other means: great accuracy and star-tracker can find its location again after satellite was restarted or lost in space.
\subsubsection{Horizon Sensors}
Earth horizon sensors use infra-red radiation from the Earth's surface via use of bolometer. The device detects when infra-red signal was first detected and then lost. The time between is used to determine the Earth's width, what later can be used to determine roll angle. In other words device detects the contrast between the cold of deep space and the heat of Earth's atmosphere. Problems of this sensors are the fact that Earth is not perfectly circular and sensors detect infra-red in the atmosphere, which varies depending on the latitude.
\subsubsection{Magnetometer}
The device actually consists of three magnetometers - one for measuring Earth's magnetic field in each direction. Measurements can be compared with known magnetic field given by International Geomagnetic Reference Field model. The problem with this sensors is that they are susceptible to noise and outside of Earth's orbit it is completely unpredictable.
\subsubsection{Global Navigation Satellite System}
Nowadays nearly everyone has personal device with Global Navigation Satellite System (GNSS). They are more commonly known by their implementation by various countries: Global Positioning System (GPS) by USA, GLONASS by Russia, Galileo by European Union, and in close future BeiDou by China. It is possible to use GNSS to determine spacecraft's attitude. This is possible when at least four GNSS satellites are visible by spacecraft, what provides three-dimensional position. Even though it gives quite good accuracy, but it decreases with the altitude. GPS satellites are located on Medium Earth Orbit (MEO), around 20,200 km above sea \cite{gps-gov}. It is possible to navigate spacecraft between Low Earth orbit (LEO -  160 to 2,000 km) and Geosynchronous Orbit (GEO - 35,786 km) \cite{nasa-gps-navigation}. For missions beyond Earth's orbit GNSS navigation is however not useful. Example of GNSS usage for navigation in space is International Space Station (ISS), which uses GPS. \cite{iss-gps}. There are however works that claim it could make using GPS systems possible for attitude determination up to Moon attitude in the future \cite{capuano2014gnss}.

\subsubsection{Conclusions}
The above means of attitude determination are usually used together with the use of Kalman filter, to compensate errors of one sensor with the other. However none of the means is more accurate than star-trackers.
Sun sensors can provide very accurate measurements, but can only operate in sunlight. For low-Earth orbit (LEO), even 30\% of the orbit can be done in the darkness. Magnetometers are small and can give accurate measurements if properly calibrated. Their drawback is the limited knowledge of the magnetic field and electromagnetic interference due to highly integrated construction of CubeSats.
Microelectromechanical gyroscopes are small enough to fit into a CubeSats. However, they suffer from sudden movements, and could not maintain the correct measurement of the 15-minute period of the eclipse orbit LEO. GPS navigation is accurate, however only on Earth's orbit. To be truly competitive and reliable platform, CubeSats must provide the correct determination of attitude. The best way to meet this goal is via using star-trackers. The typical accuracies of different sensors are available in Table \ref{tab:sensors}.

\renewcommand{\arraystretch}{1.5}
\begin{table}[!htbp]
\centering
\begin{tabular}{|p{5cm}|p{5cm}|}
\hline 
\textbf{Sensor} & \textbf{Accuracy} (less is better) \\ 
\hline 
Inertial Measurement Unit & 0.001\degree /hr to 1\degree /hr \\ 
\hline 
Sun Sensors & 0.005\degree{} to 3\degree \\ 
\hline 
Star Sensors & 0.0003\degree{} to 0.01\degree \newline (1 arc sec to 1 arc min) \\ 
\hline 
Horizon Sensors & 0.05\degree{} (GEO) \newline 0.1\degree{} (LEO) \\ 
\hline 
Magnetometer & 1.0\degree{} (5000km alt) \newline 5.0\degree{} (200 km alt) \\ 
\hline 
\end{tabular}
\caption{Sensor Accuracy Ranges. Adapted from \citet{hall2003spacecraft} and \citet{larson1992space}}
\label{tab:sensors}
\end{table}

\subsection{On-board computer}
This section describes the on-board computer (OBC) which was done as part of other thesis and is the basis for this work. Due to no existing of-the-shelf CubeSat's on-board computer with navigation module, it was designed by \citet{gaska2016obc}. The OBC can work in two modes: managing CubeSat's systems with navigation module (star-tracker) or as navigation module only. Figure \ref{fig:obc-photo} shows the mentioned OBC, while Table \ref{tab:obc-all} describes the OBC's technical parameters.

The possible tasks that can be realized by OBC are: operating on-board satellite's modules, navigation in space, auto-diagnosis, carrying out the mission.

Orientation estimation requires much more hardware resources and more power demand than other tasks executed by OBC. The OBC was designed to be able to calculate estimated attitude 2 to 5 times per second. Algorithm uses data from optic sensor and star catalogue that is placed in internal Flash memory of OBC.

\begin{figure}[!htbp]
\includegraphics[scale=0.45]{obc_photo.png}
\centering
\caption{On-board computer designed by \citet{gaska2016obc}.}
\label{fig:obc-photo}
\end{figure}

\subsubsection{The design of OBC}

\begin{figure}[!htbp]
\includegraphics[scale=0.41]{obc_all.png}
\centering
\caption{OBC schema\cite{gaska2016obc}.}
\label{fig:obc-all}
\end{figure}

The OBC is built with:
\begin{itemize}
\item two redundant main micro-controllers (TMS570) which:
\begin{itemize}
\item provide communication with other satellite's modules via I2C, UART and CAN interfaces,
\item read from external Flash memory the scheduled tasks and execute them,
\item obtain current time from the external RTC,
\item communicate with supervisor via UART interface,
\item store current mission status and tasks in FRAM external memory,
\item communicate with FPGA via SPI interface; they read the results of the work of built-in algorithms and can download the compressed image from the camera,
\item have the ability to change the internal configuration of the FPGA,
\end{itemize}

\item programmable FPGA:
\begin{itemize}
\item performs data acquisition from two cameras,
\item places the received image in the external SDRAM,
\item executes star-tracker algorithm,
\item supports SpaceWire\footnote{Interface used in space devices, designed for fast data transfer between satellite's modules. The maximum transmission rate is 400 Mbps.} interface,
\end{itemize}

\item SDRAM - memory of DDR SDRAM type for temporal storage of received image frames from both star-tracker and secondary cameras

\item Supervisor - a micro-controller that acts as supervisor. Its tasks are:
\begin{itemize}
\item detecting the suspension of the active main micro-controller and thus disconnecting it from the on-board computer subsystem, activating the redundant main micro-controller,
\item resetting micro-controllers,
\item transferring information about the power budget to the active micro-controller,
\item voltage measurement on power lines,
\item receiving data from current consumption measurement systems,
\item switching off the corresponding inverter in case of detecting overvoltage or power consumption excess.
\item turning on or off camera modules,
\item temperature measurement in key PCB places,
\item taking control of the I2C bus connected to the communication module to retrieve the current embedded software for the main micro-controllers; updating firmware in the main micro-controllers (TMS570),
\item communication with FPGA via UART interface,
\item reporting on the status of the on-board computer,
\end{itemize}

\item Power Supply - subsystem responsible for providing a number of stable voltages powering OBC electronics, equipped in special integrated circuits responsible for measuring current on the individual power lines,

\item Camera 1 - star-tracker image sensor module with the lens; the data from this camera is used by star-tracker program,

\item Camera 2 - additional image sensor module for taking pictures and recording short films,

\item FRAM - non-volatile ferroelectric memory that stores sensitive data of micro-controller software,

\item RTC - real time clock providing the current date and time.

\end{itemize}


\begin{table}[!htbp]
\centering
\begin{tabular}{|p{5cm}|p{6cm}|}\hline 
 & \textbf{Designed OBC module} \\ 
\hline 
\textbf{Architecture} & Two independent \newline micro-controllers with \newline Cortex-R4F core \\ 
\hline 
\textbf{Frequency} & 180MHz \\ 
\hline 
\textbf{FPGA} & Cyclone III EP3C25Q240 \\ 
\hline 
\textbf{RAM} & 128MB \\ 
\hline 
\textbf{Flash memory} & 16MB + 2MB \\ 
\hline 
\textbf{FRAM} & 256KB \\ 
\hline 
\textbf{RTC} & Yes \\ 
\hline 
\textbf{CAN interface} & 1x \\ 
\hline 
\textbf{I2C interface} & 2x \\ 
\hline 
\textbf{SpaceWire interface} & possibile to implement \\ 
\hline 
\textbf{Image sensor interface} & 2x (star-tracker camera and additional camera) \\ 
\hline 
\textbf{Solutions increasing resistance to radiation} & Yes \\ 
\hline 
\end{tabular} 
\caption{OBC's technical parameters. Adapted from \citet{gaska2016obc}.}
\label{tab:obc-all}
\end{table}


\subsubsection{Main processing module} 

The main processing system is build with Texas Instrument's TMS570LS3137 with two Cortex-R4F cores in lockstep mode - both cores execute the same instructions and the results are compared; if they are different, the instructions are repeated. Both cores are operating in FreeRTOS, but can be easily moved into SafeRTOS. Table \ref{tab:obc-main-processor} describes hardware resources of this micro-controller and Figure \ref{fig:obc-main-processor} show schema of this module.


\begin{table}[!htbp]
\centering
\begin{tabular}{|p{4cm}|p{3cm}|}\hline 
\textbf{Resource} & \textbf{Amount} \\ 
\hline 
Flash memory & 3 MB \\ 
\hline 
RAM & 256kB \\ 
\hline 
Frequency & 160Mhz \\ 
\hline 
FlexRay & 1 \\ 
\hline 
CAN bus & 3 \\ 
\hline 
SPI & 3 \\ 
\hline 
I2C & 1 \\ 
\hline 
UART & 2 \\ 
\hline 
ADC canals & 24 \\ 
\hline 
\end{tabular} 
\caption{Resources of Texas Instrument's TMS570LS3137. Adapted from \citet{gaska2016obc}.}
\label{tab:obc-main-processor}
\end{table}


\begin{figure}[!htbp]
\includegraphics[scale=0.49]{obc_main_processor.png}
\centering
\caption{OBC main processing system schema\cite{gaska2016obc}.}
\label{fig:obc-main-processor}
\end{figure}


\subsubsection{Supervisor module} 

The supervisor unit is build with ATmega128 micro-controller, what is visible in Figure \ref{fig:obc-supervisor}.

\begin{figure}[!htbp]
\includegraphics[scale=0.48]{obc_supervisor.png}
\centering
\caption{OBC supervisor system schema \cite{gaska2016obc}.}
\label{fig:obc-supervisor}
\end{figure}

\subsubsection{Star-tracker module}

The FPGA used in star-tracker module is Altera's EP3C25Q240. Table \ref{tab:obc-fpga} describes the resources of the mentioned FPGA module. In this FPGA 32-bit soft-processor NIOS II was implemented in Fast version. It can work with 175MHz frequency and achieve 195 DMIPS. The elements generated together with processor are:
\begin{itemize}
\item memory protection unit (MPU),
\item external interrupt controller,
\item 2kb cache memory,
\item 4kb instruction set memory,
\item address space up to 4 GB,
\item 6-step pipeline,
\item JTAG interface.
\end{itemize}


\begin{table}[!htbp]
\centering
\begin{tabular}{|p{6cm}|p{3cm}|}
\hline 
\textbf{Resource} & \textbf{Amount} \\ 
\hline 
Logical elements & 24624 \\ 
\hline 
M9K blocks & 66 \\ 
\hline 
RAM & 0.06Mbit \\ 
\hline 
Hardware multiplying blocks & 66 \\ 
\hline 
PPL & 4 \\ 
\hline 
I/O lines & 148 \\ 
\hline 
Differential pairs & 43 \\ 
\hline 
\end{tabular} 
\caption{Resources of Altera's EP3C25Q240. Adapted from \citet{gaska2016obc}.}
\label{tab:obc-fpga}
\end{table}


Another element of star-tracker module is SDRAM memory. By using two Micron's two parallel 64MB DDR SDRAM MT46V64M8 in total 128MB was achieved, where temporary image frames from cameras are stored.

The last part are cameras. Here only the star-tracker camera module is described, because the other camera is not important for this work. The star-tracker camera is based on CMOS MT9D111 sensor. It contains built-in JPEG compressor and consumes little energy. It is equipped in parallel interface with 8-bit bus for data transfer and I2C interface for configuring basic image parameters and many other sensor options, i.e. JPEG compression, coding type, etc. The Table \ref{tab:obc-camera} describes the most important sensor parameters.


\begin{table}[!htbp]
\centering
\begin{tabular}{|p{5cm}|p{5cm}|}
\hline 
\textbf{Parameter} & \textbf{Value} \\ 
\hline 
\textbf{Format} & 1/3.2" \\ 
\hline 
\textbf{Resolution} & 1600x1200 pixels \\ 
\hline 
\textbf{Max frame rate} & 15 fps \\ 
\hline 
\textbf{ADC resolution} & 10 bits \\ 
\hline 
\textbf{Output data format} & YCbCr, 565RGB, 555RGB,\newline 444RGB, JPEG 4:2:2,\newline JPEG 4:2:0 \\ 
\hline 
\textbf{Additional pros} & Built-in JPEG compressor \\ 
\hline 
\end{tabular} 
\caption{Most important parameters of MT9D111 sensor. Adapted from \citet{gaska2016obc}.}
\label{tab:obc-camera}
\end{table}

\begin{figure}[!htbp]
\includegraphics[scale=0.5]{obc_startracker.png}
\centering
\caption{OBC star-tracker system schema \cite{gaska2016obc}.}
\label{fig:obc-startracker}
\end{figure}


\newpage
\section{Preliminaries}
\subsection{Earth's orbits}

Most of spacecrafts' missions take place on Earth's orbits. There exist a variety of different classifications of orbits. Here will be presented only a few necessary to understand the topic.

Centric classification:

\begin{itemize}
\item geocentric - orbit around Earth
\item heliocentric - orbit around the Sun
\item Lunar orbit - orbit around the Earth's moon
\end{itemize}

Orbital period classification:

\begin{itemize}
\item geosynchronous - period of rotation is equal to one sidereal day (23 hours, 56 minutes, and 4 seconds) in the same direction as Earth. This results that satellite stays in the same meridian, but can move in the North-South axis. The altitude of such orbits is 35,786 km above sea level.
\item geostationary - Special case of geosynchronous orbit. A geostationary orbit stays exactly above the equator. For the observer on the surface the satellite stays always at the same point in the sky. Most commercial communication, broadcast and Satellite-Based Augmentation System (SBAS - system complementing GNSS) satellites use geostationary orbits.
\item semi-synchronous - orbit has an orbital period of ½ sidereal day. The example here are orbits of GPS satellites.
\end{itemize}

Altitude classification:

\begin{itemize}

\item Low Earth orbit (LEO): altitudes from 160 to 2,000 km. Used among others for ISS, Earth observation and spy satellites, some communication satellites like Iridium phones network, Hubble Space Telescope. Every object on altitude below 160 km will quickly loose it's altitude and it's orbit will decay.
\item Medium Earth orbit (MEO): altitudes from 2,000 km to 35,786 km. Used for navigation, communication, space environment science. Most commonly used is the altitude approximately 20,00 km, because it has orbital period of ½ sidereal day. It is used for example by GPS. Other GNSS satellites' orbits are 19,000 km for GLONASS and 23,222 km for Galileo.
\item Geosynchronous (GSO) and Geostationary (GEO) orbits - altitude approximately 35,786 km.
\item High Earth orbit: altitude above 35,786 km. Orbital periods are longer than 1 sidereal day.

\end{itemize}

The mentioned orbits are visible to some extend in the Figure \ref{fig:orbits-image}. Of course this is just a small variety of possible orbits, however describing more is not necessary for the purpose of this work.


\begin{figure}[!htbp]
\includegraphics[scale=0.7]{Comparison_satellite_navigation_orbits.png}
\centering
\caption{Earth's satellites navigation orbits \cite{orbits-image}}
\label{fig:orbits-image}
\end{figure}


\subsection{Coordinate frames}
Describing attitude is not that simple outside Earth's surface. Earth rotates and moves around the Sun, therefore it is necessary to understand means needed for correct attitude description.
Below are described a few important frames important for understanding this work. 

\subsubsection{ECEF frame}
Earth-Centered, Earth-Fixed frame is visible in Figure \ref{fig:ecef_frame}. Its x axis points towards intersection between Greenwich Meridian and equator, while its z-axis points along the rotation axis of the Earth. The y-axis completes a right handed orthogonal coordinate system. The origin of the frame is at the center of the Earth.
This all means that the coordinates move together with Earth's rotation. It is good frame for representing objects on Earth's surface, but not for objects in space.

\begin{figure}[!htb]
\includegraphics[scale=0.4]{eci_frame.jpg}
\centering
\caption{ECEF frame, Image from \citet{larson1992space}}
\label{fig:ecef_frame}
\end{figure}

\subsubsection{ECI frame}
The Earth Centered Inertial frame is similar to ECEF, with the difference that it is inertial - it does not follow Earth's rotation, but stays the same despite the planet's rotation. The origin of the frame is at the center of the Earth. It is much better frame for representing objects in space.
\citet{larson1992space}

\subsubsection{NED frame}
The North East Down frame is represented in Figure \ref{fig:ned_frame}. Its z-axis points downwards, perpendicular to the tangent plane of Earth. The x-axis points towards true north and the y-axis points East. The NED frame is an inertial frame - not dependent on Earth's rotation.

\begin{figure}[!htb]
\includegraphics[scale=0.6]{ned_frame.jpg}
\centering
\caption{NED frame \cite{ned-frame-image}}
\label{fig:ned_frame}
\end{figure}

\subsubsection{BODY frame}
In this frame the origin is the centre of the spacecraft. The moves and rotates with the spacecraft. The x-axis points forward from spacecraft, the y-axis points to the right side and the z-axis points downwards. The frame is represented in Figure \ref{fig:body_frame}.

\begin{figure}[!htb]
\includegraphics[scale=0.5]{body_frame.jpg}
\centering
\caption{BODY frame, Image from \citet{larson1992space}}
\label{fig:body_frame}
\end{figure}

\subsection{Space environment?}

\subsection{CCD vs CMOS?}

\subsection{Attitude representations}
Attitude is not only were one object is located relative to other, but also how it is rotated. It is possible to represent attitude in few ways. Here are described two most commonly used for such case: Euler angels and quaternions. Quaternions are used in all presented estimation methods.

\subsubsection{Euler angles}

Euler angles were described by Leonard Euler in 1776 \cite{euler1775formulae}. They are used for representing an orientation of an object.
To fully understand the orientation between two frames it is necessary to have three parameters: one angle for the rotation around each axis. Those angles are called roll, pitch, yaw typically written as $\phi$, $\theta$ and $\psi$ respectively. The Euler angles are often used for the definition of rotation matrices about the x, y and z-axis. The equations \ref{eq:euler_rx}, \ref{eq:euler_ry} and \ref{eq:euler_rz} describe those rotation matrices.

\begin{equation} \label{eq:euler_rx}
\bm{R}_x(\phi) = \begin{bmatrix}
1 & 0 & 0 \\
0 & \cos(\phi) & -sin(\phi) \\
0 & \sin(\phi) & \cos(\phi)
\end{bmatrix}
\end{equation}
\begin{equation} \label{eq:euler_ry}
\bm{R}_y(\theta) = \begin{bmatrix}
\cos(\theta) & 0 & \sin(\theta) \\
0 & 1 & 0 \\
-\sin(\theta) & 0 & \cos(\theta)
\end{bmatrix}
\end{equation}
\begin{equation} \label{eq:euler_rz}
\bm{R}_z(\psi) = \begin{bmatrix}
\cos(\psi) & -\sin(\psi) & 0 \\
\sin(\psi) & \cos(\psi) & 0 \\
0 & 0 & 1
\end{bmatrix}
\end{equation}

\subsubsection{Quaternions}

In 1843 Sir William Rowan Hamilton described quaterions \citet{hamilton1844lxxviii} and in 1845 multiplication of quaternions to describe rotations were published by Arthur Cayley \citet{cayley1845xiii}. Quaternions consist of four elements: three give the coordinates and fourth describing angle of rotation \citet{courant1953methods}.
A quaternion can be described as a four-dimensional vector:
\begin{equation}
\bm{q} \coloneqq \begin{bmatrix}
q_0 \\
q_1 \\
q_2 \\
q_3
\end{bmatrix}
\end{equation}

where real part can be described using a rotation angle $v$, as follows:
\begin{equation}
q_0 = \cos(v/2)
\end{equation}

\begin{equation}
\bm{n} = \frac{\bm{n}}{||\bm{n}||}
\end{equation}
The imaginary part can be written as a vector:
\begin{equation}
\bm{q}_{vec} \coloneqq \begin{bmatrix}
q_1 \\
q_2 \\
q_3
\end{bmatrix}
= [\bm{n}\sin(v/2)]
\end{equation}
where $\bm{n} = \frac{\bm{n}}{||\bm{n}||}$.

\subsubsection{Advantages of quaternions}

Quaternions are easier to use in calculations, have more compact notation and errors easier to handle than in matrix representation. Also normalization of quaternions is easier and cheaper computationally than normalization of matrices.
The most important advantage of quaternions over Euler angles is being safe from gimbal lock. Gimbal lock is the loss of one degree of freedom that occurs when axes of two of three gimbals are driven into a parallel configuration. This could lead to real disaster \citet{shoemake1985animating}.

Quaternions show many advantages, and due to possible spins of CubeSat, quaternions are the only logical choice to be used for attitude estimation methods.


\newpage
\section{Star-tracker program}

Star-tracker program is designed to determine the attitude of the satellite with the image of the stars made by the satellite camera. Before the start of the mission star catalogue is generated, based on the star catalogues obtained from the observatories on Earth and uploaded to the computer on-board the satellite. 

After the start, the satellite is released from rocket's tank in space and has no idea where it is. Then the star-tracker on the satellite enters into Lost-In-Space mode (LIS) and analyses the current image of the stars of the camera, and then searches the corresponding result of stars in the on-board star catalogue database. If it finds an entry in the database, the satellite goes into tracking mode. This means each next calculation of the orientation of the satellite attitude is going to be based on a comparison of the current pictures of stars with the preceding ones. If it cannot find the result in the database, this action is repeated from time to time, until a match is found in the database and the program will go into tracking mode.

Of course LIS does not happen only at the beginning of the satellite's flight, but can also result from many causes, e.g. a satellite which is for a long time in the darkness may discharge its battery, and during the next entry into sunlit zone will turn on and look again its attitude. Another case is when satellite becomes lost, although once found the orientation and follow her. This happens, because the successive results are based on preceding ones and even the smallest mistake will grow until the satellite will not be able to correctly calculate their attitude. It may also happen that the satellite will rotate around its axis so fast that the program would not keep up with the processing the image and calculations. In this case, the corresponding other satellite's systems should take an action reducing his spin, but this is not part of this work. It is showed in simple conceptual diagram - Figure \ref{fig:startracker_conceptual_alg}.

\begin{figure}[ht]
\includegraphics[scale=0.59]{startracker_eng.jpg}
\centering
\caption{Startracker conceptual algorithm diagram}
\label{fig:startracker_conceptual_alg}
\end{figure}

Each part - LIS and tracking - consists of smaller algorithms. Lost-In-Space at the beginning of reading an image from the camera, thresholds the image. Thresholding is basically throwing away parts of the image which do not exceed the threshold brightness, making just bright enough stars taken into account. Next it calculates centroid (center of mass) of selected stars, identifies these stars using one of the possible methods (here Planar Triangle, described later) and searches the directory on-board technology (k-vector).
If the database does not contain corresponding stars, the algorithm returns to the input state and starts analysing the next image. If it manages to find the corresponding stars, the program determines the attitude of the satellite (by what angle is satellite shifted comparing to the referenced object - Earth or previous image) and enters tracking mode. Tracking mode is in large part similar to the LIS. The algorithm also first analyses the photo, selects and calculates centroids stars, identifies them, but does not search for stars in the directory board. In this algorithm are compared two images, one following after the other, and on this basis the current attitude is calculated.

Generally star-tracker is divided into three main parts\citet{mcbryde2012star}:
\begin{itemize}
\item recognizing stars on the image and converting the data into list of star vectors by calculating star centroids;
\item identifying which star vector represents which real star in catalogue. This is done by comparing star vectors from the image with data in star catalogue, which is generated before space mission;
\item estimating the attitude by calculating the displacement between two frames.
\end{itemize}

\subsection{Centroid - star recognition}

The whole star-tracker program is based on very precise calculations. For this reason, the calculation based on the position of the pixels only can give incorrect results. It is necessary to calculate the position of stars with an accuracy exceeding pixels. This is why the calculation of the star centroids is necessary.

The first step is the determination of stars' position in the plane of the image. If focused star pictures are recorded, the image of each star will fall only on one or two pixels, and most likely the saturate these pixels, resulting in a pixel level accuracy.
Many star-trackers are doing deliberately blurred images, in order to spread the photons on a larger number of pixels, which allows the algorithm for calculating the centroid in sub-pixel accuracy.

After the registration of such image, the centroid of the star is found similarly to the centroid weight points array, with a few differences. Firstly, instead of weight light intensity is used. Secondly, the intensity of light is usually normalized by the pixels around the star in order to filter out glare or noise. The resulting outcome is a series of two-dimensional coordinates on the photo plane with the starting point at the center of the image. This allows the system to the coordinates of the stars can be easily converted into unit vectors in the next step.

The algorithm requires specification of the light intensity threshold (to select the brightest stars) $I_{thresh}$ and the size of the Region of Interest (ROI) $a_{ROI}$ in pixels. These values are adjusted to manipulate the performance of the algorithm. For example, the higher the value of $I_{thresh}$ is more resistant to noise, but can miss some real stars in the picture. Similarly, a large value $a_{ROI}$ means a more exact value of centroid, but the algorithm can see one star there, where are actually two within a short distance of each other. The centroiding part is about trade-off between noise resistance and star recognition, and also between recognizing few close stars as one and recognizing one big star as a few.
Please note that $a_{ROI}$ must be a positive odd number for the proper functioning of the algorithm.


The idea of how to calculate such centroids is adapted from \citet{mcbryde2012star} and described below:

\begin{enumerate}
\item For each pixel at image coordinates (x,y) with light intensity $I(x,y) > I_{thresh}$, the ROI is defined as the square of pixels with side length $a_{ROI}$ and bottom-left corner at $(x_{start},y_{start})$
\begin{equation}
x_{start} = x - \frac{a_{ROI} - 1}{2}
\end{equation}
\begin{equation}
y_{start} = y - \frac{a_{ROI} - 1}{2}
\end{equation}
\begin{equation}
x_{end} = x_{start} + a_{ROI}
\end{equation}
\begin{equation}
y_{end} = y_{start} + a_{ROI}
\end{equation}
\item If $x_{start} < 0$ or $y_{start} < 0$, discard the pixel and return to previous step with the next pixel.

\item Find the average intensity value of the border pixels
$I_{border}$
\begin{subequations}
\begin{equation}
I_{bottom} = \sum_{i=1}^{x_{end}-1} I(i, y_{start})
\end{equation}
\begin{equation}
I_{top} = \sum_{i=2}^{x_{end}} I(i, y_{end})
\end{equation}
\begin{equation}
I_{left} = \sum_{j=1}^{y_{end}-1} I(x_{start}, j)
\end{equation}
\begin{equation}
I_{right} = \sum_{j=2}^{y_{end}} I(x_{start}, j)
\end{equation}
\begin{equation}
I_{border} = \frac{I_{top} + I_{bottom} + I_{left} + I_{right}}{4(a_{ROI} - 1)}
\end{equation}
\end{subequations}

\item Normalize all the non-boarder pixels, yielding normalized light intensity matrix $\tilde{I}$

\begin{equation}
\tilde{I}(x,y) = I(x,y) - I_{border}
\end{equation}

\item Calculate centroid locations $(x_{CM}, y_{CM})$ and brightness $B$
\begin{equation}
B = \sum_{i=x_{start}+1}^{x_{end}-1}\sum_{j=y_{start}+1}^{y_{end}-1}\tilde{I}(i,j)
\end{equation}
\begin{equation}
x_{CM} = \sum_{i=x_{start}+1}^{x_{end}-1}\sum_{j=y_{start}+1}^{y_{end}-1}\frac{i \times \tilde{I}(i,j)}{B}
\end{equation}
\begin{equation}
x_{CM} = \sum_{i=x_{start}+1}^{x_{end}-1}\sum_{j=y_{start}+1}^{y_{end}-1}\frac{j \times \tilde{I}(i,j)}{B}
\end{equation}

\item When the centroid location has been calculated for each pixel above the intensity threshold, it is still necessary to make clustering of them. This is done via averaging together all values that are clustered together. Before clustering it is sure that some stars will have more centroids than one, and clustering helps merge them into one. It is configurable by the number of proximity pixels of the centroids. Of course it is not possible to do it perfectly. The main problem is that sometimes there are few stars in close proximity to each other on the photo and it is possible to count those few stars as one, while doing this correctly for all other stars in the photo. On the other hand, if threshold is lowered too much, it is possible to count few stars correctly, but also possible to count one star as a few. The Figure \ref{fig:centroids-examples} shows example of such trade-off.
The clustering can be accomplished by checking each new centroid against a list of already processed centroids. If the new location is within the given range (for example 5 pixels) it is assumed they represent the same star and therefore they values are averaged. The output of this step is the list of star centroids, where each centroid should represent separate star.


\item Now convert each found centroid location into unit vector $\bm{u}$ using the camera pixel size $\mu$ and camera focal length $f$

\begin{equation}
\bm{u} = \frac{
\begin{bmatrix}
\mu x_{CM} & \mu y_{CM} & f
\end{bmatrix}
^T}
{||
\begin{bmatrix}
\mu x_{CM} & \mu y_{CM} & f
\end{bmatrix}
||}
\end{equation}
\end{enumerate}

\begin{figure}[!htbp]
  \centering
  \subfloat[Original image]{\includegraphics[width=0.5\textwidth]{centroids_1.jpg}\label{fig:centroids_1}}
  \hfill
  \subfloat[Too high pixel proximity threshold]{\includegraphics[width=0.5\textwidth]{centroids_2.png}\label{fig:centroids_2}}
  \hfill
  \subfloat[Too low pixel proximity threshold]{\includegraphics[width=0.5\textwidth]{centroids_3.png}\label{fig:centroids_3}}
  \hfill
  \subfloat[Ideal result of clustering]
{\includegraphics[width=0.5\textwidth]{centroids_4.png}\label{fig:centroids_4}}
  \caption{Example of centroids' clustering trade-off (in negative colours).}
  \label{fig:centroids-examples}
\end{figure}

\subsection{Star identification}

Star identification is the part of star-tracker program, which actually finds out which recognized stars are which. Prior this part it is only known that some stars were read from the image, and now it is the time to identify them by comparing to on-board star catalogue. There is a number of techniques to do that\cite{spratling2009survey}. In this chapter most of them will be described.


\subsubsection{Angle Matching}
The Angle Matching is probably the oldest way for identifying stars. It needs at least two stars as an input\cite{gottlieb1978star}. The Figure \ref{fig:angle_matching} visualizes the way the method works.

\begin{figure}[ht]
\includegraphics[scale=0.7]{vector_angle_method.jpg}
\centering
\caption{Vector angle method, Image \citet{gottlieb1978star}}
\label{fig:angle_matching}
\end{figure}

The angle between two vectors pointing to the stars is given by:

\begin{equation}
\theta = \cos^{-1}(\bm{r}_1 \cdot \bm{r}_2)
\end{equation}
where $\bm{r}_1$ and $\bm{r}_2$ are unit vectors pointing to each star. The vectors are given in inertial space. The angle $\theta$ is the same when inertial vectors or body vectors are used. The problem is that the angle measured between stars in the image contain significant measurement error, that cannot be ignored.
What is needed by this technique, is the standard deviation of the angle between two stars when each star measurement possesses the error described. It can be used to provide a bound on the expected errors.
Firstly standard coordinate transformation is necessary:
\begin{equation}
\bm{b}_i = A\bm{r}_i
\end{equation}
where $\bm{r}_i$ is direction the direction of star in the ECI coordinate system, $A$ is the direction cosine matrix, $\bm{b}_i$ is direction of star in the star-tracker body coordinate system.

Nearly all the probability of errors is focused on a very small area about the direction of $A\bm{r}_i$, that the sphere containing that point can be approximated by a tangent plane, characterized by:
\begin{equation}
\tilde{\bm{b}}_i = A\bm{r}_i + \bm{v}_i, \hspace{0.5cm} \bm{v}_i^TA\bm{r}_i = 0
\end{equation}
where $\tilde{\bm{b}}_i$ is the it{i}th measurement and sensor $\bm{v}_i$ is approximately Gaussian, which satisfies
\begin{subequations}
\begin{equation}
E\left\{\bm{v}_i\right\} = 0
\end{equation}
\begin{equation}
E\left\{\bm{v}_i\bm{v}_i^T\right\} = \sigma_i^2 [\bm{I} - (A\bm{r}_i)(A\bm{r}_i)^T]
\end{equation}
\end{subequations}
where $\sigma_i^2$ is the variance and $E$ is expectation.
The dot product of two body observations gives
\begin{equation}
\bm{b}_1^T\bm{b}_2 = \bm{r}_1^TA^TA\bm{r}_2 = \bm{r}_1^T\bm{r}_2
\end{equation}
what show that the dot product is attitude-invariant measurement.
In case of two measurements $\bm{b}_1$ and $\bm{b}_2$ with noise, where $\bm{v}_1$ and $\bm{v}_2$ are uncorrelated:
\begin{subequations}
\begin{align*}
\tilde{\bm{b}}_1 = A\bm{r}_1 + \bm{v}_1\\
\tilde{\bm{b}}_2 = A\bm{r}_2 + \bm{v}_2
\end{align*}
\end{subequations}
define the effective measurement:
\begin{equation}
z \equiv \tilde{\bm{b}}_1^T\tilde{\bm{b}}_2 = \bm{r}_1^T\bm{r}_2 + \bm{r}_1^TA^T\bm{v}_J + \bm{r}_2^TA^T\bm{v}_1 + \bm{v}_1^T\bm{v}_2
\end{equation}
As $\bm{v}_1$ and $\bm{v}_2$ are uncorrelated, then:
\begin{equation}
E\left\{z\right\} = \bm{r}_1^T\bm{r}_2
\end{equation}
Define the following variable:
\begin{equation}
p \equiv z - E\left\{z\right\} = \bm{r}_1^TA^T\bm{v}_J + \bm{r}_2^TA^T\bm{v}_1 + \bm{v}_1^T\bm{v}_1
\end{equation}
Taking $E\left\{p^2\right\}$ gives the variance for the dot product measurement error:
\begin{equation}
\begin{split}
\sigma_p^2 \equiv E\left\{p^2\right\} = \\
\bm{r}_1^TA^TR_2A\bm{r}_1 + \bm{r}_2^TA^TR_aA\bm{r}_2 + Trace(R_1R_2) = \\
Trace(A\bm{r}_1\bm{r}_1^TR_2) + Trace(A\bm{r}_2\bm{r}_2^TR_1) + Trace(R_1R_2)
\end{split}
\end{equation}
where $E\left\{\bm{v}_1\bm{v}_1^T\right\}\equiv R_1$ and $E\left\{\bm{v}_2\bm{v}_2^T\right\}\equiv R_2$.

The effective measurement noise in the dot product consist of both Gaussian and chi-squared distribution, but since the noise is small in comparison to the unit vector observation, the effective noise can be treated as purely Gaussian. As the attitude is not known, the $A\bm{r}_1$ and $A\bm{r}_2$ are replaced by $\tilde{\bm{b}}_1$ and $\tilde{\bm{b}}_2$. Errors introduced in this substitution are second-order in nature, hence the variance is completely independent of the attribute matrix $A$.

In case there exist more than one possible solution, so called pivoting is made. This means that if for first angle more than one solution was found, the second angle is selected, that shares one common star with the first angle. When all solutions for second angle are obtained, the solutions not common for those two angles are discarded. If there is still more than one solution, then another pivot is made. Now it compares the second angle with third angle, with a common star. The rest goes analogically. This happens till finally there is only one solution for some two angles, or there are no more angles left in the input, and system enters into LIS mode.

\subsubsection{Spherical Triangle Matching}

Instead of measuring the inter-star angle, this method creates spherical triangles out of three stars. Due to that more information can be obtained from such triangle than an angle, what enables to identify stars faster and using fewer stars overall than in previous method. In this technique the area and polar moment are used instead of angles. The main disadvantage comparing to angle matching method is that this one requires not two but three stars in order to work properly, however under typical conditions in angle matching it is necessary to use more stars due to measurement error. Also the spherical triangle catalogue is about 10 times larger than angle catalogue\cite{cole2004fast}.

\begin{figure}[ht]
\includegraphics[scale=0.29]{spherical_triangle_method.jpg}
\centering
\caption{Spherical Triangle Method, Image \citet{cole2004fast}}
\label{fig:spherical_triangle_method}
\end{figure}
Given three unit vectors pointing toward three stars, the area of a spherical triangle is as follows:
\begin{equation}
A = 4\tan^{-1}\sqrt{\tan\frac{s}{2}\tan\frac{s-a}{2}\tan\frac{s-b}{2}\tan\frac{s-c}{2}}
\end{equation}
where
\begin{subequations}
\begin{align*}
s = \frac{1}{2}(a + b + c) \\
a = \cos^{-1} \bigg(\frac{\bm{b}_1 \cdot \bm{b}_2}{|\bm{b}_1||\bm{b}_2|}\bigg) \\
b = \cos^{-1} \bigg(\frac{\bm{b}_2 \cdot \bm{b}_3}{|\bm{b}_2||\bm{b}_3|}\bigg) \\
c = \cos^{-1} \bigg(\frac{\bm{b}_3 \cdot \bm{b}_1}{|\bm{b}_3||\bm{b}_1|}\bigg) 
\end{align*}
\end{subequations}
The equation is given for the body frame, but can be used in the ECI frame too. To get a bound for the measurement error, the standard deviation must be calculated.

The polar moment is good supplement to area, because it is possible for two spherical triangles to have the same area but different polar moment, and all way around. This helps to quickly reduce the number of possible solutions.

The polar moment can be obtained as follows
\begin{equation}
I_p = \sum\theta^2dA
\end{equation}

The polar moment of each spherical triangle is calculated by recursive algorithm, which divides the triangle into smaller triangles till the recursion's depth is met.

The standard deviations for area and polar moment are given in \citet{cole2004fast}.

In this technique pivoting works analogically to the angle matching method. Note that while calculation of the standard deviation of area is quite straightforward, the standard deviation of the second moment calculation is difficult to compute analytically.

\subsubsection{Planar Triangle}

The third technique, quite similar to previous one is Planar Triangle. Instead of spheres it uses planes, what makes it much less computationally demanding. It also uses the same two properties: triangle area and polar moment. In this case also three stars are necessary\cite{cole2006fast}.

\begin{figure}[ht]
\includegraphics[scale=0.30]{planar_triangle_method.jpg}
\centering
\caption{Planar Triangle Method, Image \citet{cole2006fast}}
\label{fig:planar_triangle_method}
\end{figure}

Given thee unit vectors pointing toward three stars $\bm{u_p}$, $\bm{u_q}$, $\bm{u_r}$, the area for planar triangle is as follows:
\begin{equation}
A = \sqrt{s(s-a)(s-b)(s-c)}
\end{equation}
where
\begin{subequations}
\begin{equation}
s = \frac{1}{2}(a + b + c)
\end{equation}
\begin{equation}
a = ||\bm{u_p} - \bm{u_q}||
\end{equation}
\begin{equation}
b = ||\bm{u_q} - \bm{u_r}||
\end{equation}
\begin{equation}
c = ||\bm{u_p} - \bm{u_r}||
\end{equation}
\end{subequations}

The equation is given for the body frame, similarly as for the spherical triangle. It can be also used for ECI frame. Also here the standard deviation has to be calculated in order to obtain a bound of the measurement error.

Similarly as in the previous method, here also polar moment is calculated:
\begin{equation}
J = A\frac{(a^2 + b^2 + c^2)}{36}
\end{equation}

Since the planar area is a nonlinear function, a linearization must be used to determine its variance. To compute this, the following matrix must be evaluated:

Derivatives
\begin{equation}
H = \begin{bmatrix}
\bm{h}_1^T & \bm{h}_2^T & \bm{h}_3^T
\end{bmatrix}
\end{equation}
where
\begin{subequations}
\begin{equation}
\bm{h}_1^T \equiv \frac{\delta A}{\delta a}\frac{\delta a}{\delta\bm{b}_1} + \frac{\delta A}{\delta c}\frac{\delta c}{\delta\bm{b}_1}
\end{equation}
\begin{equation}
\bm{h}_2^T \equiv \frac{\delta A}{\delta a}\frac{\delta a}{\delta\bm{b}_2} + \frac{\delta A}{\delta b}\frac{\delta b}{\delta\bm{b}_2}
\end{equation}
\begin{equation}
\bm{h}_3^T \equiv \frac{\delta A}{\delta b}\frac{\delta b}{\delta\bm{b}_3} + \frac{\delta A}{\delta c}\frac{\delta c}{\delta\bm{b}_3} 
\end{equation}
\end{subequations}
To calculate the partials with respect to $a$, $b$ and $c$ serve the following equations:
\begin{subequations}
\begin{equation}
\frac{\delta A}{\delta a} = \frac{u_1 - u_2 + u_3 + u_4}{4A}
\end{equation}
\begin{equation}
\frac{\delta A}{\delta b} = \frac{u_1 + u_2 - u_3 + u_4}{4A}
\end{equation}
\begin{equation}
\frac{\delta A}{\delta c} = \frac{u_1 + u_2 + u_3 - u_4}{4A}
\end{equation}
\end{subequations}
where
\begin{subequations}
\begin{equation}
u_1 = (s - a)(s - b)(s - c)
\end{equation}
\begin{equation}
u_2 = s(s - b)(s - c)
\end{equation}
\begin{equation}
u_3 = s(s - a)(s - c)
\end{equation}
\begin{equation}
u_4 = s(s - a)(s - b)
\end{equation}
\end{subequations}
The partials with respect to $\bm{b}_1$, $\bm{b}_2$ and $\bm{b}_3$ are calculated formulas
\begin{subequations}
\begin{equation}
\frac{\delta a}{\delta \bm{b}_1} = (\bm{b}_1 - \bm{b}_2)^T /a, \hspace{0.5cm} \frac{\delta a}{\delta \bm{b}_2} = -\frac{\delta a}{\delta \bm{b}_1}
\end{equation}
\begin{equation}
\frac{\delta b}{\delta \bm{b}_2} = (\bm{b}_2 - \bm{b}_3)^T /b, \hspace{0.5cm} \frac{\delta b}{\delta \bm{b}_3} = -\frac{\delta b}{\delta \bm{b}_2}
\end{equation}
\begin{equation}
\frac{\delta c}{\delta \bm{b}_1} = (\bm{b}_1 - \bm{b}_3)^T /c, \hspace{0.5cm} \frac{\delta c}{\delta \bm{b}_3} = -\frac{\delta c}{\delta \bm{b}_1}
\end{equation}
\end{subequations}
The variance of the area is as follows
\begin{equation}
\sigma_A^2 = HRH^T
\end{equation}
where
\begin{equation}
R \equiv \begin{bmatrix}
R_1 & 0_{3x3} & 0_{3x3} \\
0_{3x3} & R_2 & 0_{3x3} \\
0_{3x3} & 0_{3x3} & R_3
\end{bmatrix}
\end{equation}

As with the area, it is necessary to obtain the variance of the polar moment. The following partial matrix has to be evaluated first:

\begin{equation}
\bar{H} = \begin{bmatrix}
\bar{\bm{h}}_1^T & \bar{\bm{h}}_2^T & \bar{\bm{h}}_3^T
\end{bmatrix}
\end{equation}
where
\begin{subequations}
\begin{equation}
\bar{\bm{h}}_1^T \equiv \frac{\delta J}{\delta a}\frac{\delta a}{\delta\bm{b}_1} + \frac{\delta J}{\delta c}\frac{\delta c}{\delta\bm{b}_1} + \frac{\delta J}{\delta A}\bm{h}_1^T
\end{equation}
\begin{equation}
\bar{\bm{h}}_2^T \equiv \frac{\delta J}{\delta a}\frac{\delta a}{\delta\bm{b}_2} + \frac{\delta J}{\delta b}\frac{\delta b}{\delta\bm{b}_2} + \frac{\delta J}{\delta A}\bm{h}_2^T
\end{equation}
\begin{equation}
\bar{\bm{h}}_3^T \equiv \frac{\delta J}{\delta b}\frac{\delta b}{\delta\bm{b}_3} + \frac{\delta J}{\delta c}\frac{\delta c}{\delta\bm{b}_3} + \frac{\delta J}{\delta A}\bm{h}_3^T
\end{equation}
\end{subequations}
with
\begin{subequations}
\begin{equation}
\frac{\delta J}{\delta a} = A a/18, \hspace{0.5cm} \frac{\delta J}{\delta a} = A b/18, \hspace{0.5cm} \frac{\delta J}{\delta a} = A c/18
\end{equation}
\begin{equation}
\frac{\delta J}{\delta A} = (a^2 + b^2 + c^2)/36
\end{equation}
\end{subequations}
Other quantities are given from the area variance calculations. The variance of the polar moment is calculated with the following formula:
\begin{equation}
\sigma_J^2 = \bar{H}R\bar{H}^T
\end{equation}

Pivoting works analogically as in the previous methods.

This method gives similar results as spherical triangle method, but planar triangle method does not have to perform recursive calculations of polar moment like the previous method, hence it has lower computational demand for star-identification\cite{alidoost2013review}.	


\subsubsection{Pyramid}

Pyramid method is described by \citet{mortari2004pyramid}. This algorithm is designed to be used efficiently with 4-star input, however can also function for 3-star input if no more are available. It uses set of star pairs in elementary measured star polygons (3 for a triangle, six for a 4-star pyramid). The vertices between adjacent measured star pairs share a common catalogued star.

The Figure \ref{fig:pyramid_method} shows how the algorithm works. If there are less than 3 stars on input, the algorithm returns error, what actually brings back to start of the algorithm with new input data. In case there are three stars only, algorithm gets rid of redundant solutions, and if the solution is unique, the stars are identified and solution is outputted. In case of not finding unique solution, algorithm returns an error, and starts again with new data. If there are more than three stars, algorithm gets three stars for a triangle, and then one reference star. Later it checks pairs of reference star and triangle's vertices. If unique solution is found, it identifies the remaining stars and outputs all the identified stars. If no unique solution has been found, algorithm tries to get new triangle and repeat the steps. There are two possible exits of this loop: the already mentioned finding unique solution, or running out of new triangles. In the last case algorithm removes redundant solutions, then check again if it is unique solution. Finally either unique solution is found and algorithm identifies all other stars from the input and outputs them, or returns an error and stars again with the new input data.

\begin{figure}[!htbp]
\includegraphics[scale=0.57]{pyramid_method.jpg}
\centering
\caption{Pyramid Method Flowchart, Image \citet{mortari2004pyramid}}
\label{fig:pyramid_method}
\end{figure}

According to authors the algorithm can solve LIS problem and is highly robust. The key to algorithm's efficiency lies in the usage of k-vector method and the usage of expected random frequencies connected to matching interstar angles from measured star polyhedron. The algorithm has been tested on Draper’s “Inertial Stellar Compass” star tracker\cite{brady2002inertial} and on MIT’s satellites HETE and HETE-2\cite{crew2002hete} successfully. This algorithm is currently under exclusive contract to StarVision Technologies\cite{jacox2006method}\cite{pyramid-starvision}.


\subsubsection{Voting}
Algorithm was presented by \citet{kolomenkin2008geometric}. Pair of stars in the catalogue votes for a pair of stars in the image if angular distance between the stars of both pairs is similar. Since angular distance is a symmetric relationship, each catalogue star in the pair vote for each in the image pair. Then the image star is identified as the catalogue star which gave the most votes.

Authors' testing has shown that the algorithm is as accurate, as fast and more robust than other methods. The authors tested the algorithm in simulation only, and it does not appear to be tested in space yet. Furthermore, all simulations and testing were done on assumption of slow rotation, hence it is not known how it would function in the real environment. The more details about this algorithm can be found in \citet{kolomenkin2008geometric}.


\subsubsection{Grid}
The Grid Algorithm was designed by \citet{padgett1997grid}. The main ideas of the algorithm are to generate a specified pattern database and to construct a grid pattern from the measured star field in the CCD plane. The specified pattern is designed by using grids. Then the measured grid pattern is identified by best matching pattern in the database.According to authors the algorithm is robust and comparable with other methods in terms of accuracy and performance. 

This algorithm will not be described in more detail, since it is designed for CCD camera, and this thesis focuses on star-tracker for OBC mentioned before, which uses CMOS camera. More information can be found in \citet{padgett1997grid}.


\subsubsection{Other techniques}

Other techniques involve: 

\begin{itemize}
\item Spherical-Polygon (SP) Search by \citet{mortari1999sp}:

The idea of this method is that any star direction can be expressed as a linear combination of two non-parallel star directions (star pair basis) together with their vector cross-product. The star identification problem is transformed into the simpler problem of finding which stars, within a large star catalogue, are admissible with a given direction. This is solved by approximating a cone with a spherical polygon and search for all of the three components of the given direction. 

\item Star Neighbourhood Approach by \citet{samaan2005recursive}:

This method does not solve LIS problem, but can be used only in star-tracker's tracking mode. The algorithm makes use of the knowledge of the previous frame data to initiate the current frame star.


\item Brightness Independent 4-Star Matching Algorithm by \citet{dong2006brightness}:

This technique needs at least 4 stars as an input, than calculates angular separations between each pair, and tries to find corresponding star pairs with similar angular separations in the database.
Identified stars are not used again, and the remaining stars are used with additional stars to make a new 4-star group. Then this step is repeated. In case no star was identified, at least one star will be removed to build a new 4-star group. If there would be no more than 4 stars left, then already identified stars have to be used.
No information about real-life usage has been found.

\item Use of neural networks and machine learning algorithms:

\begin{itemize}
\item 'Star Identification using Neural Networks' by \citet{lindbladstar} describes approach to star identification in two different ways: Radial Basis Funcion (RBF) Neural Network and k Nearest Neighbours,

\item Parallel Backpropagation (BP) multi-subnets are designed by \citet{li2003star},

\item Method based on Delunay Triangulation algorithm and neural networks is designed by \citet{miri2012star}.

\end{itemize}
\end{itemize}


\subsubsection{Conclusions}

From the described techniques the Planar Triangle method was chosen. Comparing to Angle Method it gives better results and comparing to Spherical Triangle it less computationally demanding\cite{tappe2009development}\cite{alidoost2013review}. It requires more memory for the database, but it is still in range of the designed OBC. Pyramid technique cannot be used as it is patented.
Algorithms based on neural networks need significantly more computational power and memory. What is more, no information about the usage of such algorithms on real spacecraft was found.
As for other algorithms, Star Neighbourhood does not support LIS mode, for Brightness Independent, SP-Search, Voting and Grid methods no information about real-life use was found. Moreover Planar Triangle was tested in at least two other works (but only against Angle and Spherical Triangle Methods), and was chosen as giving the best overall results.

\subsection{Star-catalogue and searching for matching stars}

\subsubsection{Star Catalogue Generation}
\citet{mcbryde2012star}
\begin{equation}
\bm{u} = \begin{bmatrix}
\cos \alpha \cos \delta \\
\sin \alpha \cos \delta \\
\sin \delta
\end{bmatrix}
\end{equation}
\begin{equation}
m_i \leq m_{max}
\end{equation}
\begin{equation}
m_j \leq m_{max}
\end{equation}
\begin{equation}
\bm{u_a^T u_b} \geq \cos \theta_{FOV}
\end{equation}

\subsubsection{Candidate Matching}
to be removed?
\subsubsection{Result Verification}
to be removed?
\subsubsection{Search Less Algorithm and k-vector}

Search Less Algorithm (SLA) citet{mortari2000k} is special algorithm used to speed up looking up the corresponding stars in the on-board computer. Its heart is k-vector technique. Comparing to binary search technique, k-vector demonstrates high speed gain rate, from 10 to more than 50 times \cite{mortari2000k}.

The k-vector database is built before spacecraft's start. The k-vector table is a structural database of all catalogued star pairs that could possibly fit into the camera FOV over the whole sky. 
The star pairs are ordered with increasing inter-star angle \cite{mortari1996fast}.

The k-vector technique works in the following way: $\bm{y}$ is the data vector of $n$ elements $(n \gg 1)$ and $\bm{s}$ is the same vector but sorted in ascending mode: $\bm{s}(i) \le \bm{s}(i+1)$, and $\bm{s}(i) = \bm{y}(\bm{I}(i))$, where $\bm{I}$ is the integer vector of the sorting with length $n$ \cite{mortari2013k}.


\begin{figure}[!htbp]
\includegraphics[scale=0.57]{k-vector-example.png}
\centering
\caption{K-vector technique example, Image from \citep{mortari2000k}}
\label{fig:k-vector-example}
\end{figure}


In the Figure \ref{fig:k-vector-example} it is shown how such k-vector construction looks like. In this example the database has 10 elements. X-axis describes k-vector elements $\bm{k}(i)$ and y-axis describes the sorted values $\bm{s}(i)$ (inter-star angle in this case). The value of $\bm{k}(i)$ represents the number of elements of the database vector $\bm{y}$ below the value $z(i)$.
The resulting k-vector is $\bm{k} = \{0, 2, 2, 3, 3, 5, 6, 8, 9, 10\}^T$.

The following equations describe how the k-vector database is created. The line connecting two extreme points, $[1, y_{min}]$ and $[n, y_{max}]$, has to be a little stepper and connect points $[1, y_{min}-\delta\epsilon]$ and $[n, y_{max}+\delta\epsilon]$. This assures $\bm{k}(1) = 0$ and $\bm{k}(n	) = n$ and simplifies the code by avoiding many index checks.
\begin{equation}
z(x) = mx + q \begin{cases}m = \frac{y_{max} - y_{min} + \delta\epsilon}{n - 1} \\
q = y_{min} - m - \delta\epsilon \end{cases}
\end{equation}
\begin{equation}
\delta\epsilon = (n - 1)\epsilon
\end{equation}
$\epsilon$ is relative machine precision for double precision arithmetic
\begin{equation}
\epsilon \approx 22.2 \times 10^{-16}
\end{equation}
Each other element can be found using the following equation:
\begin{equation}
\bm{k}(i) = j \hspace{0.5cm} where \hspace{0.5cm} s(j) \leq z(i) < s(j + 1)
\end{equation}
or
\begin{equation}
\bm{k}(i) = j \hspace{0.5cm} \textnormal{where j is the greatest index such} \hspace{0.5cm} s(j) \leq \bm{y}	(\bm{I}(i)) \hspace{0.5cm} \textnormal{is satisfied.}
\end{equation}

At this point k-vector has been built, and further use is quite simple. The equation to find indices identifying in $\bm{s}$ vector all possible data within the range $[y_a, y_b ]$ is following:

\begin{equation}
j_b = \Big\lfloor\frac{y_a - q}{m}\Big\rfloor \hspace{0.5cm} and \hspace{0.5cm} j_t = \Big\lceil\frac{y_b - q}{m}\Big\rceil
\end{equation}
In the example of Figure \ref{fig:k-vector-example} it is $j_b = 4$ and $j_t = 9$. After indices are evaluated it is possible to calculate
\begin{equation}
k_{start} = \bm{k}(j_b) + 1 \hspace{0.5cm} and \hspace{0.5cm} k_{end} = \bm{k}(j_t)
\end{equation}

Finally, having found $k_{start}$ and $k_{end}$ it is immediately known, that searched elements are $\bm{y}(i) \in [y_a, y_b]$, which are all the $\bm{y}(\bm{I}(i))$ where $k$ ranges from $k_{start}$ and $k_{end}$.

Note that in example the searched elements should be $k_{start} = 4$ and $k_{end} = 8$ while the presented technique returns $k_{start} = 4$ and $k_{end} = 9$. This happens due to fact that $k_{start}$ and $k_{end}$ have $50\%$ possibility to not belong to the $[y_a, z(j_a +1)]$ and $[z(j_b), y_b)]$ ranges respectively.

\subsection{Attitude Determination}
\citet{jenssen2011comparison}\par
AIM (Attitude estimation using Image Matching)\citet{delabie2012highly}\par
all \citet{hall2003spacecraft} \citet{markley1999estimate}
\subsubsection{q-method}

\begin{equation}
\bm{s}_b = \bm{R}^{bi}\bm{s}_i \hspace{0.5cm} \bm{m}_b = \bm{R}^{bi}\bm{m}_i
\end{equation}

\begin{equation}
\begin{split}
J &= \frac{1}{2} \sum w_k (\bm{v}_{kb} - \bm{R}^{bi} \bm{v}_{ki})^T (\bm{v}_{kb} - \bm{R}^{bi} \bm{v}_{ki}) \\ 
&= \frac{1}{2} \sum w_k (\bm{v}_{kb}^T\bm{v}_{kb} + \bm{v}_{ki}^T\bm{v}_{ki} + 2\bm{v}_{kb}^T \bm{R}^{bi} \bm{v}_{ki})
\end{split}
\end{equation}


\begin{equation}
J = \sum w_k (1 - \bm{v}_{kb}^T \bm{R}^{bi} \bm{v}_{ki})
\end{equation}

\begin{equation}
g(\bm{R}) = \sum w_k \bm{v}_{kb}^T \bm{R}^{bi} \bm{v}_{ki}
\end{equation}

\begin{equation}
\bm{R} = (q_4^2 - \bm{q}^T\bm{q})1 + 2\bm{qq}^T - 2q_4\bm{q}^{\bm{x}}
\end{equation}

\begin{equation}
\bm{\bar{q}}^T\bm{\bar{q}} = 1
\end{equation}

\begin{equation}
g(\bm{\bar{q}}) = \bm{\bar{q}}^T\bm{K}\bm{\bar{q}}
\end{equation}

\begin{equation}
\bm{K} = \begin{bmatrix}
\bm{S} - \sigma\bm{I} & \bm{Z} \\
\bm{Z}^T & \sigma
\end{bmatrix}
\end{equation}

\begin{equation}
\bm{B} = \sum_{k=1}^Nw_k(\bm{v}_{kb}\bm{v}_{ki}^T)
\end{equation}

\begin{equation}
\bm{S} = \bm{B} + \bm{B}^T
\end{equation}

\begin{equation}
\bm{Z} = \begin{bmatrix}
B_{23} - B_{32} & B_{32} - B_{13} & B_{12} - B_{21}
\end{bmatrix} ^T
\end{equation}

\begin{equation}
\sigma = tr[\bm{B}]
\end{equation}

\begin{equation}
g'(\bm{\bar{q}}) = \bm{\bar{q}}^T\bm{K}\bm{\bar{q}} - \lambda\bm{\bar{q}}^T\bm{\bar{q}}
\end{equation}

\begin{equation}
\bm{K}\bm{\bar{q}} = \lambda\bm{\bar{q}}
\end{equation}

\begin{equation}
g(\bm{\bar{q}}) = \bm{\bar{q}}^T\bm{K}\bm{\bar{q}} = \bm{\bar{q}}^T\lambda\bm{\bar{q}} = \lambda\bm{\bar{q}}^T\bm{\bar{q}} = \lambda
\end{equation}

\subsubsection{Wahba's problem}

The developed extended QUEST method described in this report builds upon the principles
of Wahba’s problem. The problem was first stated by Grace Wahba in 1965 \citet{wahba1965least}. Given
two sets of vector observations, a rotation matrix $\bm{M}$ can be found which minimizes the
orientation error. This is an optimization problem, where the cost function is:

\begin{equation}
\sum_j^n ||\bm{r}_j - \bm{Mb}_j||
\end{equation}

For satellite attitude determination, the vectors $\bm{r}_j$ for $j \in \left\{1, n\right\}$ are the reference sensor data given in the NED frame. The vectors $\bm{b}_j$ for $j \in \left\{1, n\right\}$  are the measured sensor data in the BODY frame. $\bm{M}$ is the least squares estimate of the rotation matrix which carries the known frame of reference into the satellite fixed frame of reference.
The QUEST method uses this problem in order to minimize the attitude estimation error.
\subsubsection{QUEST}
improvement to quest implementation \citet{cheng2014improvement} \par
kallman filtering \citet{shuster1990kalman}
\begin{equation}
\begin{split}
J(\bm{q}) = \frac{1}{2}\sum_{j=1}^n\frac{1}{\sigma_j^2}(\bm{b}_j - \bm{R}_b^i(\bm{q})\bm{r}_j)^T(\bm{b}_j - \bm{R}_b^i(\bm{q})\bm{r}_j) = \\
\frac{1}{2}\sum_{j=1}^n\frac{1}{\sigma_j^2}(\bm{b}_j^T\bm{b}_j - 2\bm{b}_j^T\bm{R}_b^i(\bm{q})\bm{r}_j + \bm{r}_j^T\bm{r}_j)
\end{split}
\end{equation}
\begin{equation}
J(\bm{q}) = \sum_{j=1}^n\frac{1}{\sigma_j^2}(1 - \bm{b}_j^T\bm{R}_b^i(\bm{q})\bm{r}_j)
\end{equation}
\subsubsection{TRIAD}
a must
\subsubsection{The Fast Optimal Attitude Matrix}
to be removed?
\subsubsection{DCM (Direction Cosine Matrix) - Singular Value Decomposition?}
\citet{juang2003efficient}
 and

\citet{mcbryde2012star}
\begin{equation}
\bm{B = \sum_{i=1}^nb_ir_i^T}
\end{equation}
\begin{equation}
\bm{B = USV^T}
\end{equation}
\begin{equation}
\bm{U}_+ = \bm{U}\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & det\bm{U}
\end{bmatrix}
\end{equation}
\begin{equation}
\bm{V}_+ = \bm{V}\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & det\bm{V}
\end{bmatrix}
\end{equation}
\begin{equation}
\bm{A = U_+V_+^T}
\end{equation}
\newpage
\section{Prototype}
For now the following parts are finished in Python:
\begin{enumerate}
\item Centroiding
\item Planar Triangle Recognition with variations (nearly - without equation 44)
\item Pyramid alg ?
\item k-vector
\item QUEST (not started yet)
\end{enumerate}
Testing\par
\citet{kruijff2003star}, \citet{kruijff2003automated}, \citet{dzamba2014ground}, 
\newpage
\section{Complete program}

\newpage
\section{Testing of star-tracker}
\citet{tappe2011star}

\newpage
\bibliographystyle{IEEEtranN}
\bibliography{IEEEabrv,bibfile}




\newpage

\listoftables

\newpage

\listoffigures

\newpage


\end{document}
